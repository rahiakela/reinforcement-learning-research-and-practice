{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOmVWZqm4glKsXZBV0WK+Xt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/reinforcement-learning-research-and-practice/blob/main/grokking-deep-reinforcement-Learning/02-mathematical-foundations/01_mathematical_foundations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Bandit walk environment"
      ],
      "metadata": {
        "id": "TIHdSoh7uyTU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BW is a simple grid-world (GW) environment. GWs are a common type of environment for studying RL algorithms that are grids of any size. GWs can have any model (transition and reward functions) you can think of and can make any kind of actions available.\n",
        "\n"
      ],
      "metadata": {
        "id": "tcuw7jz_uzlM"
      }
    }
  ]
}